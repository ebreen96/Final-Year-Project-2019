{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep_200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a prep notebook for my research question 2 'A summary of  visualisations and packages use.' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "* In this notebook I will begin preparation on my research question 2 \n",
    "* This research question is analysed with the 2nd larger dataset downloaded from - https://library.ucsd.edu/dc/object/bb2733859v as 'Notebook files - part 4' and 'Summary CSV data'\n",
    "\n",
    "    * First I downloaded the data: CSV file containing notebook ID's and 200,000 individual ipynb files\n",
    "    * Created functions that parsed the individual notebooks by their notebook ID in the CSV\n",
    "    * Created a dataframe's with information I needed including: \n",
    "        * Packages used \n",
    "        * Headings\n",
    "        * Display data\n",
    "    * I saved the dataframe as a CSV file in /15487912_FYP/data/CSV_files/ for analysis in notebook Analysis_200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing relevant libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253620 notebooks\n"
     ]
    }
   ],
   "source": [
    "df_nb = pd.read_csv('../data/Dataset2/csv/notebooks.csv')\n",
    "\n",
    "print('%s notebooks' % df_nb.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The data above will not be found as was to large to upload*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is Adam Rule's large CSV file containing 1.2 million notebook ID's.\n",
    "* As I am using only a snippet of this data I will cut this file to where I need it \n",
    "* The individual notebook files I downloaded had ID's from [400000:599997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([596266], dtype='int64')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb.index[df_nb['nb_id']==599997] #finding the index for notebook ID 599997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nb_new = df_nb.iloc[397481:-657353] # cutting file to only have what I need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>html_url</th>\n",
       "      <th>max_filesize</th>\n",
       "      <th>min_filesize</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>query_page</th>\n",
       "      <th>repo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596262</th>\n",
       "      <td>599993</td>\n",
       "      <td>https://github.com/adithyap/mlcs16/blob/5ae2ba...</td>\n",
       "      <td>40630903</td>\n",
       "      <td>30145143</td>\n",
       "      <td>DataViewer-onlyF2D.ipynb</td>\n",
       "      <td>DataViewer-onlyF2D.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>54208713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596263</th>\n",
       "      <td>599994</td>\n",
       "      <td>https://github.com/buds-lab/the-building-data-...</td>\n",
       "      <td>40630903</td>\n",
       "      <td>30145143</td>\n",
       "      <td>00_Temporal Data Exploration.ipynb</td>\n",
       "      <td>notebooks/00_Temporal Data Exploration.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>58021880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596264</th>\n",
       "      <td>599995</td>\n",
       "      <td>https://github.com/ltauxe/GMT_Notebooks/blob/a...</td>\n",
       "      <td>40630903</td>\n",
       "      <td>30145143</td>\n",
       "      <td>GMT_chapter_13_examples.ipynb</td>\n",
       "      <td>GMT_chapter_13_examples.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>80138033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596265</th>\n",
       "      <td>599996</td>\n",
       "      <td>https://github.com/dswirtz/UdacityCarND/blob/a...</td>\n",
       "      <td>40630903</td>\n",
       "      <td>30145143</td>\n",
       "      <td>P4_AdvancedLaneLines.ipynb</td>\n",
       "      <td>P4_AdvancedLaneFinding/P4_AdvancedLaneLines.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>75776431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596266</th>\n",
       "      <td>599997</td>\n",
       "      <td>https://github.com/ofnanezn/MIR/blob/b1733290a...</td>\n",
       "      <td>40630903</td>\n",
       "      <td>30145143</td>\n",
       "      <td>Colombia Feature Vector-Copy1.ipynb</td>\n",
       "      <td>Colombia Feature Vector-Copy1.ipynb</td>\n",
       "      <td>4</td>\n",
       "      <td>87016623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb_id                                           html_url  \\\n",
       "596262  599993  https://github.com/adithyap/mlcs16/blob/5ae2ba...   \n",
       "596263  599994  https://github.com/buds-lab/the-building-data-...   \n",
       "596264  599995  https://github.com/ltauxe/GMT_Notebooks/blob/a...   \n",
       "596265  599996  https://github.com/dswirtz/UdacityCarND/blob/a...   \n",
       "596266  599997  https://github.com/ofnanezn/MIR/blob/b1733290a...   \n",
       "\n",
       "        max_filesize  min_filesize                                 name  \\\n",
       "596262      40630903      30145143             DataViewer-onlyF2D.ipynb   \n",
       "596263      40630903      30145143   00_Temporal Data Exploration.ipynb   \n",
       "596264      40630903      30145143        GMT_chapter_13_examples.ipynb   \n",
       "596265      40630903      30145143           P4_AdvancedLaneLines.ipynb   \n",
       "596266      40630903      30145143  Colombia Feature Vector-Copy1.ipynb   \n",
       "\n",
       "                                                     path  query_page  \\\n",
       "596262                           DataViewer-onlyF2D.ipynb           4   \n",
       "596263       notebooks/00_Temporal Data Exploration.ipynb           4   \n",
       "596264                      GMT_chapter_13_examples.ipynb           4   \n",
       "596265  P4_AdvancedLaneFinding/P4_AdvancedLaneLines.ipynb           4   \n",
       "596266                Colombia Feature Vector-Copy1.ipynb           4   \n",
       "\n",
       "         repo_id  \n",
       "596262  54208713  \n",
       "596263  58021880  \n",
       "596264  80138033  \n",
       "596265  75776431  \n",
       "596266  87016623  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb_new.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the dataframe goes to notebook 599997 and we can now use to iterate and parse the individual files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing notebooks\n",
    "* Here I have created functions to parse the 200,000 notebooks.\n",
    "    * I have extracted information about:\n",
    "        * Packages used\n",
    "        * Headings\n",
    "        * Display data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find packages and headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_content_data(df):\n",
    "    \n",
    "    all_cells = []      \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        f = '../data/Dataset2/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as nb_file:\n",
    "\n",
    "            try:\n",
    "                data = json.load(nb_file)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "                \n",
    "            # get the language\n",
    "            nb_language = None\n",
    "            if 'metadata' in keys:\n",
    "                if isinstance(data, dict):\n",
    "                    metadata_keys = data['metadata'].keys()\n",
    "                else:\n",
    "                    metadata_keys = []\n",
    "            else:\n",
    "                metadata_keys = []\n",
    "            if 'language_info' in metadata_keys:\n",
    "                if isinstance(data['metadata']['language_info'], dict):\n",
    "                    lang_keys = data['metadata']['language_info'].keys()\n",
    "                else:\n",
    "                    lang_keys = None\n",
    "                if 'name' in lang_keys:\n",
    "                    nb_language = data['metadata']['language_info']['name']\n",
    "            elif 'language' in metadata_keys:\n",
    "                nb_language = data['metadata']['language']\n",
    "\n",
    "            # get data for each cell, nbformat v 4.x\n",
    "            if 'cells' in keys:\n",
    "                for i, c in enumerate(data['cells']):\n",
    "                    cell_data = get_cell_data(c, i, row['nb_id'], nb_language)\n",
    "                    all_cells.append(cell_data)\n",
    "            \n",
    "            # get data for each cell, nbformat v 2.x / 3.x\n",
    "            elif 'worksheets' in keys:\n",
    "                for j, w in enumerate(data['worksheets']):\n",
    "                    if isinstance(w, dict): \n",
    "                        worksheet_keys = w.keys()\n",
    "                    else:\n",
    "                        keys = []\n",
    "                    if 'cells' in worksheet_keys:\n",
    "                        for k, c in enumerate(w['cells']):\n",
    "                            cell_data = get_cell_data(c, k, row['nb_id'], nb_language, j)\n",
    "                            all_cells.append(cell_data)\n",
    "                \n",
    "    return all_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_data(cell, index, nb_id, nb_language, worksheet_index = None):\n",
    "\n",
    "    if isinstance(cell, dict): \n",
    "        cell_keys = cell.keys()\n",
    "    else:\n",
    "        cell_keys = [] \n",
    "    \n",
    "    # get the cell type\n",
    "    if 'cell_type' in cell_keys:\n",
    "        cell_type = cell['cell_type']\n",
    "    else:\n",
    "        cell_type = None\n",
    "    \n",
    "    headings = []\n",
    "    header_level = []\n",
    "    imports = []\n",
    "    \n",
    "   # get the imports for python, Julia, and R\n",
    "    if cell_type == 'code':\n",
    "        \n",
    "        lines_of_code = []\n",
    "        \n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_code = cell['source']\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_code = cell['source'].splitlines()\n",
    "            \n",
    "        elif 'input' in cell_keys:\n",
    "            if isinstance(cell['input'], list):\n",
    "                lines_of_code = cell['input']\n",
    "            elif isinstance(cell['input'], str):\n",
    "                lines_of_code = cell['input'].splitlines()\n",
    "                \n",
    "        if nb_language == 'python':\n",
    "            import_words = ['import', 'from']\n",
    "        elif nb_language == 'R':\n",
    "            import_words = ['library', 'require']\n",
    "        elif nb_language in ['Julia', 'julia']:\n",
    "            import_words = ['import', 'importall', 'using']\n",
    "        else:\n",
    "            import_words = []\n",
    "            \n",
    "        # get imports\n",
    "        for l in lines_of_code:\n",
    "            words = l.split()\n",
    "            if len(words) >1:\n",
    "                if words[0] in import_words:                    \n",
    "                    imports.append(words[1])\n",
    "    \n",
    "    \n",
    "    elif cell_type in ['heading', 'markdown']:\n",
    "        \n",
    "        \n",
    "        # get the lines of markdown\n",
    "        lines_of_markdown = []\n",
    "        if 'source' in cell_keys:\n",
    "            if isinstance(cell['source'], list):\n",
    "                lines_of_markdown = cell['source']\n",
    "            elif isinstance(cell['source'], str):\n",
    "                lines_of_markdown = cell['source'].splitlines()\n",
    "        \n",
    "        # track headings in heading cells\n",
    "        if 'level' in cell_keys:\n",
    "            if 'source' in cell_keys:\n",
    "                if len(lines_of_markdown) > 0:\n",
    "                    headings.append([cell['level'], cell['source']])\n",
    "        \n",
    "        for l in lines_of_markdown:\n",
    "            # get headings in markdown cells\n",
    "            words = l.split()\n",
    "            if len(words) > 2:\n",
    "                if words[0] in ['#', '##', '###', '####', '#####', '######']:\n",
    "                    headings.append(len(words[0]))\n",
    "                    header_level.append(words[0])\n",
    "                \n",
    "    return [nb_id, nb_language, index, worksheet_index, len(imports), imports, len(headings), headings, header_level]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The cell below takes 2 and a half hours to run\n",
    "* I have also not included the large dataset in the data folder but can upload if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the notebook dataframe through function to iterate over each notebook and extract information\n",
    "new_cell_data = get_cell_content_data(df_nb_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4819241, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>nb_language</th>\n",
       "      <th>worksheet_index</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>num_imports</th>\n",
       "      <th>imports</th>\n",
       "      <th>num_headings</th>\n",
       "      <th>headings</th>\n",
       "      <th>header_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>julia</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[DataFrames,]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400000</td>\n",
       "      <td>julia</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400000</td>\n",
       "      <td>julia</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400000</td>\n",
       "      <td>julia</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400000</td>\n",
       "      <td>julia</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_id nb_language  worksheet_index  cell_index  num_imports  \\\n",
       "0  400000       julia                0         NaN            1   \n",
       "1  400000       julia                1         NaN            0   \n",
       "2  400000       julia                2         NaN            0   \n",
       "3  400000       julia                3         NaN            0   \n",
       "4  400000       julia                4         NaN            0   \n",
       "\n",
       "         imports  num_headings headings header_level  \n",
       "0  [DataFrames,]             0       []           []  \n",
       "1             []             0       []           []  \n",
       "2             []             0       []           []  \n",
       "3             []             0       []           []  \n",
       "4             []             0       []           []  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cells_new = pd.DataFrame(new_cell_data) # creating a dataframe with extracted information\n",
    "print(df_cells_new.shape) # getting shape of dataframe\n",
    "\n",
    "df_cells_new.columns = ['nb_id', 'nb_language', 'worksheet_index', 'cell_index', 'num_imports', 'imports', \n",
    "                    'num_headings', 'headings', 'header_level'] # renaming the columns\n",
    "\n",
    "df_cells_new.head(5) # printing first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to find display data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_cell_data(df):\n",
    "    \n",
    "    all_cells = []      \n",
    "   \n",
    "    for index, row in df.iterrows():\n",
    "     \n",
    "        f = '../data/Dataset2/notebooks/nb_%s.ipynb' % row['nb_id']\n",
    "        with open(f) as nb_file:\n",
    "            \n",
    "            try:\n",
    "                data = json.load(nb_file)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if isinstance(data, dict): \n",
    "                keys = data.keys()\n",
    "            else:\n",
    "                keys = []\n",
    "\n",
    "            # get data for each cell, v 4.0\n",
    "            if 'cells' in keys:\n",
    "                for i, c in enumerate(data['cells']):\n",
    "                    cell_data = get_display_data(c, i, row['nb_id'])\n",
    "                    all_cells.append(cell_data)\n",
    "            \n",
    "            # get data for each cell, v 3.0\n",
    "            elif 'worksheets' in keys:\n",
    "                for j, w in enumerate(data['worksheets']):\n",
    "                    \n",
    "                    if isinstance(w, dict): \n",
    "                        worksheet_keys = w.keys()\n",
    "                    else:\n",
    "                        keys = []\n",
    "                    \n",
    "                    if 'cells' in worksheet_keys:\n",
    "                        for k, c in enumerate(w['cells']):\n",
    "                            cell_data = get_display_data(c, k, row['nb_id'], j)\n",
    "                            all_cells.append(cell_data)\n",
    "                \n",
    "    return all_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_display_data(cell, index, nb_id, worksheet_index = None):\n",
    "    \n",
    "    if isinstance(cell, dict): \n",
    "        cell_keys = cell.keys()\n",
    "    else:\n",
    "        cell_keys = [] \n",
    "    \n",
    "    if 'cell_type' in cell_keys:\n",
    "        cell_type = cell['cell_type']\n",
    "    else:\n",
    "        cell_type = None\n",
    "        \n",
    "    # inilize output counts\n",
    "    num_display_data = 0\n",
    "    display_data_keys = []\n",
    "    \n",
    "    if 'outputs' in cell_keys:\n",
    "        for o in cell['outputs']:\n",
    "\n",
    "            if isinstance(o, dict):\n",
    "                output_keys = o.keys()\n",
    "            else:\n",
    "                output_keys = []\n",
    "\n",
    "            if 'output_type' in output_keys:\n",
    "                if o['output_type'] == 'display_data':\n",
    "                    num_display_data += 1\n",
    "                    if 'source' in cell_keys:\n",
    "                        if isinstance(cell['source'], list):\n",
    "                            display_data_keys = cell['source']\n",
    "                        elif isinstance(cell['source'], str):\n",
    "                            display_data_keys = cell['source'].splitlines()\n",
    "                        else:\n",
    "                            display_data_keys = None\n",
    "            \n",
    "                    elif 'input' in cell_keys:\n",
    "                        if isinstance(cell['input'], list):\n",
    "                            display_data_keys = cell['input']\n",
    "                        elif isinstance(cell['input'], str):\n",
    "                            display_data_keys = cell['input'].splitlines()\n",
    "                        else:\n",
    "                            display_data_keys = None\n",
    "        \n",
    "    return [nb_id, worksheet_index, index, num_display_data, display_data_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes 2 and a half hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing the notebook dataframe through function to iterate over each notebook and extract information\n",
    "display_data = get_display_cell_data(df_nb_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4819241, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_id</th>\n",
       "      <th>worksheet_index</th>\n",
       "      <th>cell_index</th>\n",
       "      <th>num_display_data</th>\n",
       "      <th>display_data_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nb_id  worksheet_index  cell_index  num_display_data display_data_keys\n",
       "0  400000              NaN           0                 0                []\n",
       "1  400000              NaN           1                 0                []\n",
       "2  400000              NaN           2                 0                []\n",
       "3  400000              NaN           3                 0                []\n",
       "4  400000              NaN           4                 0                []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_display = pd.DataFrame(display_data) # creating a dataframe with extracted information\n",
    "print(df_display.shape) # getting shape of dataframe\n",
    "\n",
    "df_display.columns = ['nb_id', 'worksheet_index', 'cell_index', 'num_display_data', 'display_data_keys'] #renaming the columns\n",
    "\n",
    "df_display.head(5) # printing first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving this dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells_new.to_csv('../data/CSV_files/new_cell_info.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_display.to_csv('../data/CSV_files/display_info.csv', index=False, encoding='utf-8')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analysis of information in new_cell_info.csv will be looked at in notebook Analysis_201 in the analysis folder.\n",
    "* Analysis of information in display_info.csv will be looked at in notebook Analysis_202 in the analysis folder.\n",
    "* new_cell_info.csv created from this notebook will also be used for my 3rd and 4th research questions which will begin in Prep_300 and Prep_400 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
